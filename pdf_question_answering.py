# -*- coding: utf-8 -*-
"""Pdf Question Answering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16EoXQVRVvuAMOGDTwWYxl84qoaqo6UAW
"""

!pip install langchain transformers PyPDF2

!pip install langchain-huggingface
!pip install huggingface_hub
!pip install transformers
!pip install accelerate
!pip install  bitsandbytes
!pip install langchain

import PyPDF2

def extract_text_from_pdf(pdf_path):
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ''
        for page in reader.pages:
            text += page.extract_text()
        return text

pdf_text = extract_text_from_pdf('/content/Resume.pdf')

from google.colab import userdata
sec_key=userdata.get("HF_TOKEN")
print(sec_key)

from langchain_huggingface import HuggingFaceEndpoint

from google.colab import userdata
sec_key=userdata.get("HUGGINGFACEHUB")
print(sec_key)

import os
os.environ["HUGGINGFACEHUB_API_TOKEN"]=sec_key

repo_id = "mistralai/Mistral-7B-Instruct-v0.3"

llm = HuggingFaceEndpoint(
    repo_id=repo_id,
    max_length=128,
    temperature=0.7
)

questions = [
    "What is the main topic of the document?",
    "Summarize the key points.",
    "What are the conclusions drawn?"
]

answers = []
for question in questions:
    prompt = f"Context: {pdf_text}\n\nQuestion: {question}"
    answer = llm.invoke(prompt)
    answers.append(answer)

for i, question in enumerate(questions):
    print(f"Question: {question}\nAnswer: {answers[i]}\n")

!pip install gradio

import gradio as gr

def extract_text_from_pdf(pdf_path):
    with open(pdf_path, 'rb') as file:
        reader = PyPDF2.PdfReader(file)
        text = ''
        for page in reader.pages:
            text += page.extract_text()
        return text

def process_pdf(pdf_file, questions):

    pdf_text = extract_text_from_pdf(pdf_file.name)

    repo_id = "mistralai/Mistral-7B-Instruct-v0.3"
    llm = HuggingFaceEndpoint(
        repo_id=repo_id,
        max_length=128,
        temperature=0.7
    )

    answers = []
    for question in questions:
        prompt = f"Context: {pdf_text}\n\nQuestion: {question}"
        answer = llm.invoke(prompt)
        answers.append(answer)

    result = "\n\n".join([f"Question: {questions[i]}\nAnswer: {answers[i]}" for i in range(len(questions))])

    return result
with gr.Blocks() as demo:
    gr.Markdown("# PDF Q&A with HuggingFace Model")

    with gr.Row():
        pdf_input = gr.File(label="Upload PDF")
        questions_input = gr.Textbox(label="Enter your questions (comma separated)", placeholder="What is the main topic of the document?, Summarize the key points.")

    output = gr.Textbox(label="Output", lines=10)

    submit_button = gr.Button("Generate Answers")

    submit_button.click(
        fn=process_pdf,
        inputs=[pdf_input, questions_input],
        outputs=output
    )

demo.launch()

